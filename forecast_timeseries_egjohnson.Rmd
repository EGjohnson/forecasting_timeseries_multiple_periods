---
title: "forecast_timeseries_egjohnson"
author: "Elizabeth"
date: "March 27, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
# import data processing and forecasting libraries
.x <- c("data.table", "readr","printr","scales","magrittr","pipeR","lubridate","ggplot2",
        "knitr","anytime","tidyr","dplyr","TTR","forecast")
lapply(.x, library, character.only = T)
setwd("~/PetGit/forecast_timeseries_multiple_periods/")
```

```{r}
# read in data as character
tcdat <- fread("app_data.csv",colClasses=c("character"))
tcdat %>% head
```


```{r}
#change UNIX timestamp to actual date
#seconds since Jan 01 1970. (UTC)
#convert characters to numeric
library(tidyr)
tcdat %>% dplyr::mutate(begin_time=anytime(as.integer(begin_time))) %>% dplyr::mutate_if(is.character,as.numeric) -> tcdat
                                                                
tcdat %>% head
```


#Throughput peaks in the middle of the day - but only on weekdays
```{r}

ggplot(tcdat, aes(x = begin_time, y = throughput)) + 
  geom_line(size =0.1) +
  scale_x_datetime(breaks = date_breaks("1 day"), labels=date_format("%a \n %d",tz=Sys.timezone()))+
  theme_bw()
```


#On a weekday throughput typically peaks prior to noon then tapers off.
```{r}
tcdat %>% dplyr::filter(day(begin_time) ==26)->tc.plot

ggplot(tc.plot, aes(x = begin_time, y = throughput)) + 
  geom_line(size =0.1) +
  scale_x_datetime(breaks = date_breaks("1 hour"),labels=time_format("%a \n %d \n %H",tz=Sys.timezone()))+
  theme_bw()
```


# response time spikes on some weekdays with random random slowdowns
```{r}
ggplot(tcdat, aes(x = begin_time, y = average_response_time)) + 
  geom_line(size = 1) +
  scale_x_datetime(breaks = date_breaks("1 day"), labels=date_format("%a-%d",tz=Sys.timezone()))+
  theme_bw()
```
# relationship between throughput and average response time
```{r}
#labels = date_format("%a-%d\n%H:%M"
response_curve <- lm(average_response_time ~ poly(throughput,4),data=tcdat)
#response_curve <-nls(average_response_time~ exp(a + b * throughput), data = tcdat, start = list(a = 0, b = 0))
pred.response<- predict(response_curve,throughput=tcdat$throughput)
tcdat.fit.plot<-cbind(tcdat,pred.response)
```

```{r}
ggplot(tcdat.fit.plot, aes(x = throughput, y = average_response_time)) + 
  geom_point(size =0.5) +
  geom_line(color='red',aes(x=throughput,y=pred.response))
  theme_bw()
  
  

```

```{r}
ggplot(tcdat.fit.plot %>% filter(average_response_time<1000), aes(x = average_response_time, y = throughput)) + 
  geom_point(size =0.5) +
  theme_bw()
```

# Decompose Timeseries into a weekly period, a daily period, trend and random noise
```{r}
tcdat.ts <- forecast::msts(tcdat$throughput,seasonal.periods = c(24*60,24*60*7-1))
tcdat.ts %>% mstl(.) ->tcdat.mstl
tcdat.mstl %>% autoplot() + xlab("Week")
```

#Forecast time series using STL decomposition and ARIMA for trend and noise component
```{r}
# STL: local regression for decomposition of cyclic components
# non seasonal arima model for trend and noise component
# 2 autoregressive terms (p)
# 1 difference needed for stationarity (d)
# 1 lagged forecast errors terms (q)

#create model that describes  4 weeks of data
tcdat.ts %>%stlf(method='arima',level=c(80,95),h =24*60*7*4) ->ts.model
#use model to forecast out 4  weeks
the.forecast<-forecast(ts.model,robust=TRUE)
plot(the.forecast)
```

```{r}
checkresiduals(ts.model)
```



```{r}
tcdat %>% mutate(begin_time2=begin_time+minutes(1)) %>%
filter(max(begin_time2)==begin_time2) %>% select(begin_time2) %>%
.$begin_time %>% as.character()->start.new.time.vec

forecast.date<-seq(from=ymd_hms(start.new.time.vec)+min(1),length.out=the.forecast$mean %>% length,by="1 min")
the.forecast %>% data.frame() %>% cbind(forecast.date) -> the.forecast
```

```{r}
new.time.seq %>% head
```


